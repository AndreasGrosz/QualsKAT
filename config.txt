[Paths]
documents = documents
check_this = CheckThis
output = output
models = models

[Models]
# Format: HuggingFace-Name,Kurzbezeichnung,Training,Checking
model_list =
    distilbert-base-uncased,distill,True,True
    roberta-large,rob-l,True,True
    roberta-base,rob-b,True,True
    microsoft/deberta-base,deb-b,True,True
    albert-base-v2,alb-b,True,True
    gpt3-6B,gpt3,False,False
    t5-large,t5-l,False,False
    allenai/longformer-base-4096,long-b,False,False
    xlnet-large-cased,xln-l,False,False
    google/electra-large-discriminator,elec-l,False,False

[DocumentsCheck]
checksum =

[Training]
batch_size = 16
learning_rate = 2e-5
num_epochs = 3
weight_decay = 0.01
warmup_steps = 500
gradient_accumulation_steps = 4

[Optimization]
fp16 = True
max_grad_norm = 1.0

[Evaluation]
eval_steps = 500
save_steps = 1000
